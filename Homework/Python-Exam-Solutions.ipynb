{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fd695efd-7226-4f72-812d-181c8b792cb1",
   "metadata": {},
   "source": [
    "# MTH 4224 / CSE 4224 - Python Exam Solutions\n",
    "\n",
    "Please note that some alternative approaches are valid and may result in full credit even if it isn't exactly like mine."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c418e2b8-d3cf-4617-b7bb-4418f06c43fc",
   "metadata": {},
   "source": [
    "## Problem 1\n",
    "\n",
    "Write a function that uses the minimum number of terms in the [Wallis product for $\\pi$](https://en.wikipedia.org/wiki/Wallis_product) to estimate $\\pi$ to within $n$ decimal places and print the number of terms used, the error, and the approximation. $n$ should be the only input. Run it for $n = 1, 2, ..., 6$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b24c4a37-9feb-4ede-959d-c71108169ad3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We approximated pi to 1 decimal places with 8 terms with error 0.0910026575342826\n",
      "3.0505899960555105\n",
      "We approximated pi to 2 decimal places with 78 terms with error 0.009989089968858167\n",
      "3.131603563620935\n",
      "We approximated pi to 3 decimal places with 785 terms with error 0.0009997111901154376\n",
      "3.1405929423996777\n",
      "We approximated pi to 4 decimal places with 7854 terms with error 9.999180897501958e-05\n",
      "3.141492661780818\n",
      "We approximated pi to 5 decimal places with 78540 terms with error 9.999896994461466e-06\n",
      "3.1415826536927987\n",
      "We approximated pi to 6 decimal places with 785398 terms with error 9.999993797471518e-07\n",
      "3.1415916535904134\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "def pi_approx(n):\n",
    "    # error is required to be < 10^-n\n",
    "    error_tolerance = 1 / 10 ** n\n",
    "    \n",
    "    # initialize the product to 2 (since the infinite product is pi/2)\n",
    "    product = 2\n",
    "    \n",
    "    # initialize the counter\n",
    "    j = 0\n",
    "    \n",
    "    # initialize the error\n",
    "    error = math.inf\n",
    "    \n",
    "    # loop until error drops below the error tolerance\n",
    "    while error > error_tolerance:\n",
    "        # iterate the counter\n",
    "        j += 1\n",
    "        \n",
    "        # multiply the product by the next term\n",
    "        product *= 4 * j ** 2 / (4 * j ** 2 - 1)\n",
    "        \n",
    "        # compute error\n",
    "        error = abs(product - math.pi)\n",
    "        \n",
    "    # print some details\n",
    "    print('We approximated pi to', n, 'decimal places with', j, 'terms with error', error)\n",
    "        \n",
    "    # return the approximation\n",
    "    return product\n",
    "        \n",
    "x = [print(pi_approx(n)) for n in range(1, 7)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4f59dda-2f7e-4524-9392-41d2e2cf1cb2",
   "metadata": {},
   "source": [
    "## Problem 2\n",
    "\n",
    "Write a function minimizes an input function with range $\\mathbb{R}$ using gradient descent starting from some input number $n$ of points. The function should return the coordinates and function value at the smallest minimum found.\n",
    "\n",
    "Run your function to attempt to minimize $f(x,y) = \\frac{\\sin x\\sin y}{(xy)^2+1}$ where $x,y\\in[-10,10]$. Explore the impact of different input $n$ values.\n",
    "\n",
    "Feel free to use the gradient descent code from class and make a decision about how to choose the starting points. Argue why your strategy is good."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d7e09d38-86d4-4203-a55d-44c958b590e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import numpy as np\n",
    "\n",
    "def gradient_descent_multistart(f, d, n, alpha, error_tolerance, max_iterations, h):\n",
    "    starting_points = np.random.uniform(-10, 10, size = (n, d))\n",
    "    \n",
    "    # initialize the minimal value and location\n",
    "    best_value = np.inf\n",
    "    best_point = 0\n",
    "    \n",
    "    # iterate through the starting points\n",
    "    for starting_point in starting_points:\n",
    "        \n",
    "        print('Running a new starting point')\n",
    "        \n",
    "        current_point = starting_point\n",
    "        \n",
    "        # initialize gradient\n",
    "        gradient = np.inf\n",
    "\n",
    "        # run gradient descent steps\n",
    "        for counter in range(max_iterations):\n",
    "            \n",
    "            gradient = compute_gradient(f, d, current_point, h)\n",
    "            \n",
    "            # if gradient is too small, it converged, exit loop\n",
    "            if np.linalg.norm(gradient) < error_tolerance:\n",
    "                print('Gradient descent converged in', counter, 'iterations.')\n",
    "                current_value = f(current_point)\n",
    "                break\n",
    "                \n",
    "            # if we reach the maximum iterations, it didn't converge, exit loop\n",
    "            elif counter == max_iterations - 1:\n",
    "                print('Gradient descent failed')\n",
    "                current_value = f(current_point)\n",
    "                break\n",
    "                \n",
    "            # take a gradient step\n",
    "            else:\n",
    "                current_point -= alpha * gradient\n",
    "                \n",
    "        # if the current value is less than the best so far, save it\n",
    "        if current_value < best_value:\n",
    "            print('Found a minimum at', current_point, 'with value', current_value)\n",
    "            best_value = current_value\n",
    "            best_point = current_point\n",
    "    \n",
    "    # return the best coordinates and value\n",
    "    return best_point, best_value\n",
    "    \n",
    "def compute_gradient(f, d, x, h):\n",
    "    gradient = np.zeros(d)\n",
    "    fx = f(x)\n",
    "    \n",
    "    for counter in range(d):\n",
    "        xUp = x.copy()\n",
    "        xUp[counter] += h\n",
    "        gradient[counter] = (f(xUp) - fx) / h\n",
    "        \n",
    "    return gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "feba3d18-3dbc-4291-b4c0-1112b5fec368",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running a new starting point\n",
      "Gradient descent converged in 19849 iterations.\n",
      "Found a minimum at [ 0.12794266 -7.74263063] with value -0.06399980455229447\n",
      "Running a new starting point\n",
      "Gradient descent converged in 6452 iterations.\n",
      "Found a minimum at [0.21879924 4.48768946] with value -0.10773251821158807\n",
      "Running a new starting point\n",
      "Gradient descent converged in 0 iterations.\n",
      "Running a new starting point\n",
      "Gradient descent converged in 49973 iterations.\n",
      "Running a new starting point\n",
      "Gradient descent converged in 5709 iterations.\n",
      "Running a new starting point\n",
      "Gradient descent converged in 0 iterations.\n",
      "Running a new starting point\n",
      "Gradient descent converged in 2211 iterations.\n",
      "Found a minimum at [ 0.86811165 -0.87588157] with value -0.3714161211486279\n",
      "Running a new starting point\n",
      "Gradient descent converged in 34259 iterations.\n",
      "Running a new starting point\n",
      "Gradient descent converged in 0 iterations.\n",
      "Running a new starting point\n",
      "Gradient descent converged in 0 iterations.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([ 0.86811165, -0.87588157]), -0.3714161211486279)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = lambda x: np.sin(x[0]) * np.sin(x[1]) / ((x[0] * x[1]) ** 2 + 1)\n",
    "gradient_descent_multistart(f, 2, 10, 0.01, 0.001, 100000, 0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76f53238-faa7-4a77-a97d-3ef25b7e6623",
   "metadata": {},
   "source": [
    "## Problem 3\n",
    "\n",
    "Write code to find how many unique words are in [*The Adventures of Sherlock Holmes*](https://www.gutenberg.org/files/1661/1661-h/1661-h.htm) by Arthur Conan Doyle.\n",
    "\n",
    "Do not import any libraries for this problem.\n",
    "\n",
    "**Hint**: copy the book into a file, use the `open` function to read it, and clean up the text into a usable form. (The `split` and `rstrip` functions might help.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6f24dbcd-8d5a-4630-bfce-1abe7f7ad0bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8904\n"
     ]
    }
   ],
   "source": [
    "# open Sherlock Holmes text copied from Project Gutenberg\n",
    "f_handle = open('SherlockHolmes.txt', encoding='utf-8')\n",
    "\n",
    "# initialize the word list and unique word count\n",
    "word_list = []\n",
    "unique_words = 0\n",
    "\n",
    "# iterate through the lines of text\n",
    "for line in f_handle:\n",
    "    # strip the line skip\n",
    "    clean_line = line.rstrip()\n",
    "    \n",
    "    # split line into a list of words\n",
    "    words = clean_line.split()\n",
    "    \n",
    "    # iterate through list of words\n",
    "    for word in words:\n",
    "        # clean up the word string\n",
    "        word = ''.join(filter(str.isalpha, word))\n",
    "\n",
    "        # if the word is not included yet, add it and increment word count\n",
    "        if word not in word_list:\n",
    "            word_list.append(word)\n",
    "            unique_words += 1\n",
    "\n",
    "# print the number of unique words\n",
    "print(unique_words)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

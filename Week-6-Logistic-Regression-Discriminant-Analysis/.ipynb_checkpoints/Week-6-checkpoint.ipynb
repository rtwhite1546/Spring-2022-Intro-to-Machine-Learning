{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5bc4065d-0deb-42fc-b620-aeb03ae430cf",
   "metadata": {},
   "source": [
    "# Week 6: Logistic Regression and Discriminant Analysis\n",
    "\n",
    "This week, we cover **logistic regression**, one of the most popular classifiers. Like the other classifiers we have seen, it computes posterior probabilities without assuming the distributions of the classes.\n",
    "\n",
    "Secondly, we will consider **discriminant analysis**, a powerful family of classifiers that construct so-called **discriminant functions** that specify decision boundaries that determine how points are assigned to classes.\n",
    "\n",
    "Unlike previously-seen classifiers, these methods do not necessarily require assuming the distribution of the classes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "055ff11d-ddca-4e8e-81e9-5a546e7f15f9",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Lecture 10: Logistic Regression\n",
    "\n",
    "In class, we discussed the logistic regression model for both binary classification and multiclass classification.\n",
    "\n",
    "## Binary Logistic Regression\n",
    "\n",
    "In this case, we predict binary labels $Y\\in\\{0, 1\\}$. Fitting the model simplifies to minimizing the **binary cross-entropy** loss function\n",
    "\n",
    "$$L(\\theta)=-\\sum\\limits_{i=1}^n y_i\\ln\\left(\\sigma\\left(\\theta^Tx_i\\right)\\right)+(1-y_i)\\ln\\left(\\sigma\\left(-\\theta^Tx_i\\right)\\right)$$\n",
    "\n",
    "where $\\theta=(\\theta_0, \\theta_1, ..., \\theta_d)^T$ are parameters of the model and $\\sigma:\\mathbb{R}\\to\\mathbb{R}$ is the **logistic** or **sigmoid** function\n",
    "\n",
    "$$\\sigma(z)=\\frac{1}{1+e^{-z}}=\\frac{e^z}{1+e^z}$$\n",
    "\n",
    "In class, we showed\n",
    "\n",
    "$$\\frac{\\partial L}{\\partial\\theta}=\\sum\\limits_{i=1}^n\\left(\\sigma\\left(\\theta^Tx\\right)-y_i\\right)x_i$$\n",
    "\n",
    "To code logistic regression, let's first import some libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "929d1704-afa6-42cf-98c9-e61365846dfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sn\n",
    "\n",
    "from sklearn import datasets\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tensorflow.keras.datasets import mnist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "688246bc-bbe9-4fd6-a0b3-eff8635a77a4",
   "metadata": {},
   "source": [
    "Next, we implement binary logistic regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "897d0076-a3e2-4dc0-bd15-929d0d9a9676",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BinaryLogisticRegression:        \n",
    "    def fit(self, X, y, alpha, epochs, eps, update):\n",
    "        # add a column of 1s to X\n",
    "        X = np.hstack((np.ones([X.shape[0],1]), X))\n",
    "            \n",
    "        # modify y to be n by 1\n",
    "        y = np.atleast_2d(y).T\n",
    "        \n",
    "        # initialize the parameters to 1\n",
    "        self.theta = np.ones([X.shape[1], 1])\n",
    "        \n",
    "        # initialize the step number and theta gradient\n",
    "        step = 0\n",
    "        thetagrad = 2 * eps\n",
    "        \n",
    "        # minimize cross-entropy -- run until thetagrad is small or step is epochs\n",
    "        while np.linalg.norm(thetagrad) > eps and step < epochs:\n",
    "            # compute the loss\n",
    "            sig = self.sigmoid(X @ self.theta)\n",
    "            \n",
    "            if step % update == 0:\n",
    "                loss = -(1/X.shape[0]) * np.sum(y * np.log(sig + 0.001) + (1 - y) * np.log(1 - sig + 0.001))\n",
    "                print('Iteration', step, '\\tLoss =', loss)\n",
    "            \n",
    "            # compute the gradient\n",
    "            thetagrad = X.T @ (sig - y)\n",
    "            \n",
    "            # take a gradient descent step\n",
    "            self.theta -= alpha * thetagrad\n",
    "                        \n",
    "            # iterate the step\n",
    "            step += 1\n",
    "            \n",
    "            if step == epochs:\n",
    "                print('Gradient descent failed to converge. (The answer may still be acceptably good.)')\n",
    "            \n",
    "    def predict(self, X):\n",
    "        # add a column of 1s to X\n",
    "        X = np.hstack((np.ones([X.shape[0],1]), X))\n",
    "        \n",
    "        # return 0 if the posterior for Y=1 is less than for Y=0\n",
    "        # otherwise, return 1\n",
    "        return (self.sigmoid(X @ self.theta) >= 0.5).astype(float)\n",
    "            \n",
    "    def sigmoid(self, z):\n",
    "        return 1 / (1 + np.exp(-z))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12af9c6a-c772-493e-a956-da7816a3c13c",
   "metadata": {},
   "source": [
    "### Example: Detecting Breast Cancer with Binary Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b3491322-9500-4112-98a1-ed67db9f8d41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0 \tLoss = 2.6424911781372944\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ryan\\AppData\\Local\\Temp/ipykernel_7116/4107300181.py:46: RuntimeWarning: overflow encountered in exp\n",
      "  return 1 / (1 + np.exp(-z))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 100000 \tLoss = 0.5179679948267453\n",
      "Iteration 200000 \tLoss = 0.53418572905049\n",
      "Iteration 300000 \tLoss = 0.43687932370802207\n",
      "Iteration 400000 \tLoss = 4.085869524050568\n",
      "Iteration 500000 \tLoss = 0.4206615894842774\n",
      "Iteration 600000 \tLoss = 0.53418572905049\n",
      "Iteration 700000 \tLoss = 0.53418572905049\n",
      "Iteration 800000 \tLoss = 0.3882261210367881\n",
      "Iteration 900000 \tLoss = 0.3882261210367881\n",
      "Gradient descent failed to converge. (The answer may still be acceptably good.)\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.78      0.87        49\n",
      "           1       0.90      1.00      0.94        94\n",
      "\n",
      "    accuracy                           0.92       143\n",
      "   macro avg       0.95      0.89      0.91       143\n",
      "weighted avg       0.93      0.92      0.92       143\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# import the breast cancer dataset\n",
    "breastcancer = datasets.load_breast_cancer()\n",
    "\n",
    "# find the data and labels\n",
    "X = breastcancer.data\n",
    "Y = breastcancer.target\n",
    "\n",
    "# split the data into train and test sets\n",
    "trainX, testX, trainY, testY = train_test_split(X, Y, test_size = 0.25)\n",
    "\n",
    "# build the classifier\n",
    "model = BinaryLogisticRegression()\n",
    "\n",
    "# fit the classifier to the training data\n",
    "model.fit(trainX, trainY, alpha = 0.01, epochs = 1000000, eps = 0.01, update = 100000)\n",
    "\n",
    "# predict the labels of the test set\n",
    "predictedY = model.predict(testX)\n",
    "\n",
    "# print quality metrics\n",
    "print('\\nClassification Report:\\n\\n', classification_report(testY, predictedY))\n",
    "print('\\nConfusion Matrix:\\n')\n",
    "\n",
    "sn.heatmap(confusion_matrix(testY, predictedY), annot = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "216c02ee-96ca-4b5c-af00-3c488a45231f",
   "metadata": {},
   "source": [
    "### Example: Detecting Breast Cancer with `LogisticRegression` from `scikit-learn`\n",
    "\n",
    "The built-in `LogisticRegression` class in `scikit-learn` tends to work a little faster because it uses an optimizer that efficiently uses second derivative information by default. Note that the class uses an $L^2$ penalty if we speciy the variable `C`, where\n",
    "\n",
    "$$C=\\frac{1}{\\lambda_2}$$\n",
    "\n",
    "Tuning this hyperparameter is a good idea to improve performance on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "049e1c9d-6878-44f6-a302-a121c16c9fb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Classification Report:\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.98       166\n",
      "           1       0.98      0.99      0.99       260\n",
      "\n",
      "    accuracy                           0.99       426\n",
      "   macro avg       0.99      0.98      0.99       426\n",
      "weighted avg       0.99      0.99      0.99       426\n",
      "\n",
      "\n",
      "Testing Classification Report:\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.91      0.93        46\n",
      "           1       0.96      0.98      0.97        97\n",
      "\n",
      "    accuracy                           0.96       143\n",
      "   macro avg       0.96      0.95      0.95       143\n",
      "weighted avg       0.96      0.96      0.96       143\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ryan\\anaconda3\\envs\\ML\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "# import the breast cancer dataset\n",
    "breastcancer = datasets.load_breast_cancer()\n",
    "\n",
    "# find the data and labels\n",
    "X = breastcancer.data\n",
    "Y = breastcancer.target\n",
    "\n",
    "# split the data into train and test sets\n",
    "trainX, testX, trainY, testY = train_test_split(X, Y, test_size = 0.25)\n",
    "\n",
    "# build the classifier\n",
    "model = LogisticRegression(C = 10000, max_iter = 10000)\n",
    "\n",
    "# fit the classifier to the training data\n",
    "model.fit(trainX, trainY)\n",
    "\n",
    "# predict the labels of the training set\n",
    "predictedY = model.predict(trainX)\n",
    "\n",
    "# print quality metrics\n",
    "print('\\nTraining Classification Report:\\n\\n', classification_report(trainY, predictedY))\n",
    "\n",
    "# predict the labels of the test set\n",
    "predictedY = model.predict(testX)\n",
    "\n",
    "# print quality metrics\n",
    "print('\\nTesting Classification Report:\\n\\n', classification_report(testY, predictedY))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60772691-ee20-42b7-81d8-67e61d056b4c",
   "metadata": {},
   "source": [
    "## Multiclass Logistic Regression\n",
    "\n",
    "Logistic regression can also be applied to classification problems with logistic regression. In this case, we predict one-hot vector labels $Y\\in\\{\\mathbf{e}_1, \\mathbf{e}_2, ..., \\mathbf{e}_k\\}$. Fitting the model simplifies to minimizing the **categorical cross-entropy** loss function\n",
    "\n",
    "$$L(\\theta)=-\\sum\\limits_{i=1}^n\\sum\\limits_{j=1}^k y_{ij}\\ln\\left(\\sigma\\left(\\theta^T_j x_i\\right)\\right)$$\n",
    "\n",
    "where $\\theta_j=(\\theta_{j0}, \\theta_{j1}, ..., \\theta_{jd})^T$ are parameters of the model for $j=1, ..., k$.\n",
    "\n",
    "In class, we derived the gradient, which can be used in gradient descent as\n",
    "\n",
    "$$\\frac{\\partial L}{\\partial\\theta_l}=\\sum\\limits_{i=1}^n \\left(\\pi_l(x_i) - y_{il}\\right)x_i=\\sum\\limits_{i=1}^n\\sum\\limits_{j=1}^k \\left(\\sigma\\left(\\theta^T x_i\\right)_l-y_{il}\\right)x_i$$\n",
    "\n",
    "where the **softmax** function $\\sigma:\\mathbb{R}^k\\to\\mathbb{R}^k$ is defined in each coordinate as\n",
    "\n",
    "$$\\sigma(z)_i=\\frac{e^{z_i}}{\\sum\\limits_{j=1}^k e^{z_j}}$$\n",
    "\n",
    "We will simply use the `scikit-learn` class `LogisticRegression` for the multiclass case to avoid some not-so-enlightening code (at least, given that it's just scaling up the binary case)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a07dfbf-b2c3-4039-9263-0282525df548",
   "metadata": {},
   "source": [
    "### Example: Classifying the Iris Dataset with Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "61e389e0-723e-4489-978e-30a93e2c9029",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicted class labels:\n",
      " [1 0 1 1 0 1 2 0 2 2 2 2 2 1 1 1 0 1 0 1 0 0 1 2 0 0 1 0 0 2 1 2 0 2 1 2 0\n",
      " 2]\n",
      "\n",
      "True class labels:\n",
      " [1 0 1 1 0 1 2 0 2 2 2 2 2 2 1 1 0 1 0 1 0 0 1 2 0 0 1 0 0 2 1 2 0 2 1 2 0\n",
      " 2]\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        13\n",
      "           1       0.92      1.00      0.96        12\n",
      "           2       1.00      0.92      0.96        13\n",
      "\n",
      "    accuracy                           0.97        38\n",
      "   macro avg       0.97      0.97      0.97        38\n",
      "weighted avg       0.98      0.97      0.97        38\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "iris = datasets.load_iris()\n",
    "\n",
    "# find the data and labels\n",
    "X = iris.data\n",
    "Y = iris.target\n",
    "\n",
    "# split the data into train and test sets\n",
    "trainX, testX, trainY, testY = train_test_split(X, Y, test_size = 0.25)\n",
    "\n",
    "# build the logistic regression classifier\n",
    "model = LogisticRegression(max_iter = 10000)\n",
    "\n",
    "# fit the logistic regression classifier to the training data\n",
    "model.fit(trainX, trainY)\n",
    "\n",
    "# predict the labels of the test set\n",
    "predictedY = model.predict(testX)\n",
    "\n",
    "# print predicted and true class labels\n",
    "print('\\nPredicted class labels:\\n', predictedY)\n",
    "print('\\nTrue class labels:\\n', testY)\n",
    "\n",
    "# print quality metrics\n",
    "print('\\nClassification Report:\\n\\n', classification_report(testY, predictedY))\n",
    "print('\\nConfusion Matrix:\\n')\n",
    "\n",
    "sn.heatmap(confusion_matrix(testY, predictedY), annot = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d52547ae-89a8-4a62-9e65-d9ba4c39d694",
   "metadata": {},
   "source": [
    "### Example MNIST Handwritten Digits with Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "504955d0-a044-4a63-9688-783d7d8c709c",
   "metadata": {},
   "outputs": [],
   "source": [
    "(trainX, trainY), (testX, testY) = mnist.load_data()\n",
    "\n",
    "# flatten the data to 768-vectors and normalize\n",
    "trainX = trainX.reshape(trainX.shape[0], trainX.shape[1] * trainX.shape[2])\n",
    "trainX = trainX.astype('float')/255.0\n",
    "\n",
    "testX = testX.reshape(testX.shape[0], testX.shape[1] * testX.shape[2])\n",
    "testX = testX.astype('float')/255.0\n",
    "\n",
    "# build the classifier\n",
    "model = LogisticRegression(max_iter = 10000)\n",
    "\n",
    "# fit the classifier to the training data\n",
    "model.fit(trainX, trainY)\n",
    "\n",
    "# predict the labels of the training set\n",
    "predictedY = model.predict(trainX)\n",
    "\n",
    "# print quality metrics\n",
    "print('\\nTraining Classification Report:\\n\\n', classification_report(trainY, predictedY))\n",
    "\n",
    "# predict the labels of the test set\n",
    "predictedY = model.predict(testX)\n",
    "\n",
    "# print quality metrics\n",
    "print('\\nTesting Classification Report:\\n\\n', classification_report(testY, predictedY))\n",
    "\n",
    "# predict the labels of the test set\n",
    "predictedY = model.predict(testX)\n",
    "\n",
    "print('\\nTesting Confusion Matrix:\\n')\n",
    "\n",
    "sn.heatmap(confusion_matrix(testY, predictedY))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c6cc816-cc7c-464c-b281-32039651c734",
   "metadata": {},
   "source": [
    "We see 93% accuracy on the test set with zero hyperparameter tuning!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bd43a14-93bb-4843-a100-46a145f84152",
   "metadata": {},
   "source": [
    "# Lecture 11: Discriminant Analysis"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
